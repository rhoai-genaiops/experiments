{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a ReAct Agent with Real Tools\n",
    "\n",
    "In this notebook, we'll build a **ReAct agent** that can autonomously reason about problems and choose from multiple real tools to solve them.\n",
    "\n",
    "**ReAct** (Reasoning + Acting) is simple but powerful:\n",
    "1. **Reason**: The LLM explains what it's thinking\n",
    "2. **Act**: The LLM calls a tool\n",
    "3. **Observe**: The tool returns results\n",
    "4. **Repeat**: Until the task is complete\n",
    "\n",
    "## The Tools We'll Use\n",
    "\n",
    "- **MCP Calendar Server**: Manage events (the 9 calendar tools you used before)\n",
    "- **RAG System**: Search through documents for information\n",
    "- **Calculator**: Simple arithmetic\n",
    "\n",
    "The agent will autonomously decide which tools to use and in what order based on the user request!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q llama-stack-client==0.3.0 mcp httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Llama Stack endpoint and Calendar MCP Server endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client.lib.inference.event_logger import EventLogger\n",
    "from mcp import ClientSession\n",
    "from mcp.client.sse import sse_client\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "import re\n",
    "import logging\n",
    "\n",
    "# Reduce noise from HTTP logs\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "# Connect to Llama Stack Server\n",
    "base_url = \"http://llama-stack-service:8321\"\n",
    "client = LlamaStackClient(base_url=base_url)\n",
    "model = \"llama32\"\n",
    "\n",
    "# MCP Server URL\n",
    "mcp_server_url = \"http://canopy-mcp-calendar-mcp-server:8080/sse\"\n",
    "\n",
    "print(f\"‚úÖ Connected to Llama Stack at: {base_url}\")\n",
    "print(f\"‚úÖ Using model: {model}\")\n",
    "print(f\"‚úÖ MCP Server: {mcp_server_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Our Tools\n",
    "\n",
    "Let's create wrapper functions for our three tool categories: Calculator, MCP Calendar, and RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 1: Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculator_tool(operation: str, a: float, b: float) -> str:\n",
    "    \"\"\"Performs basic arithmetic operations.\"\"\"\n",
    "    try:\n",
    "        if operation == \"add\":\n",
    "            result = a + b\n",
    "        elif operation == \"subtract\":\n",
    "            result = a - b\n",
    "        elif operation == \"multiply\":\n",
    "            result = a * b\n",
    "        elif operation == \"divide\":\n",
    "            if b == 0:\n",
    "                return \"Error: Cannot divide by zero\"\n",
    "            result = a / b\n",
    "        else:\n",
    "            return f\"Error: Unknown operation '{operation}'\"\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Calculator tool ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 2: MCP Calendar Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_mcp_tool(tool_name: str, arguments: Dict[str, Any]) -> str:\n",
    "    \"\"\"Call an MCP calendar tool and return the result as a string.\"\"\"\n",
    "    try:\n",
    "        async with sse_client(mcp_server_url) as (read, write):\n",
    "            async with ClientSession(read, write) as session:\n",
    "                await session.initialize()\n",
    "                result = await session.call_tool(tool_name, arguments=arguments)\n",
    "                return \"\\n\".join([content.text for content in result.content])\n",
    "    except Exception as e:\n",
    "        return f\"Error calling MCP tool: {str(e)}\"\n",
    "\n",
    "async def get_mcp_tools_description() -> str:\n",
    "    \"\"\"Get descriptions of all available MCP tools.\"\"\"\n",
    "    async with sse_client(mcp_server_url) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            tools = await session.list_tools()\n",
    "            \n",
    "            descriptions = []\n",
    "            for tool in tools.tools:\n",
    "                descriptions.append(f\"  - mcp_{tool.name}: {tool.description}\")\n",
    "            \n",
    "            return \"\\n\".join(descriptions)\n",
    "\n",
    "# Get and display available MCP tools\n",
    "mcp_tools_desc = await get_mcp_tools_description()\n",
    "print(\"‚úÖ MCP Calendar tools available:\")\n",
    "print(mcp_tools_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 3: RAG (Document Search)\n",
    "\n",
    "Let's set up the RAG system so our agent can search through documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have a vector store already, if not create one\n",
    "try:\n",
    "    # List existing vector stores\n",
    "    vector_stores = client.vector_stores.list()\n",
    "    \n",
    "    if vector_stores.data and len(vector_stores.data) > 0:\n",
    "        # Use the first available vector store\n",
    "        vector_store = vector_stores.data[0]\n",
    "        print(f\"‚úÖ Using existing vector store: {vector_store.id}\")\n",
    "    else:\n",
    "        raise Exception(\"No vector store exists\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not set up vector store: {e}\")\n",
    "    vector_store = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_search_tool(query: str, max_results: int = 3) -> str:\n",
    "    \"\"\"Search through documents using RAG and return relevant information.\"\"\"\n",
    "    if not vector_store:\n",
    "        return \"Error: RAG system not initialized. Please set up a vector store first.\"\n",
    "    \n",
    "    try:\n",
    "        # Search the vector database\n",
    "        search_results = client.vector_stores.search(\n",
    "            vector_store_id=vector_store.id,\n",
    "            query=query,\n",
    "            max_num_results=max_results,\n",
    "            search_mode=\"vector\"\n",
    "        )\n",
    "        \n",
    "        if not search_results.data:\n",
    "            return \"No relevant documents found.\"\n",
    "        \n",
    "        # Format the results\n",
    "        results = []\n",
    "        for i, result in enumerate(search_results.data, 1):\n",
    "            content = result.content if hasattr(result, 'content') else str(result)\n",
    "            results.append(f\"Result {i}: {content}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(results)\n",
    "    except Exception as e:\n",
    "        return f\"Error performing RAG search: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ RAG search tool ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the ReAct Agent\n",
    "\n",
    "Now let's build the ReAct agent that can autonomously choose which tool to use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_react_system_prompt() -> str:\n",
    "    \"\"\"Create a system prompt for the ReAct agent.\"\"\"\n",
    "    \n",
    "    return f\"\"\"You are a helpful assistant that can use tools to answer questions.\n",
    "\n",
    "Available tools:\n",
    "\n",
    "1. calculator\n",
    "   - Performs arithmetic operations (add, subtract, multiply, divide)\n",
    "   - Input format: {{\"operation\": \"add\"|\"subtract\"|\"multiply\"|\"divide\", \"a\": number, \"b\": number}}\n",
    "\n",
    "2. MCP Calendar Tools:\n",
    "{mcp_tools_desc}\n",
    "   - For calendar tools, use format: {{\"tool_name\": \"mcp_TOOLNAME\", \"arguments\": {{...}}}}\n",
    "\n",
    "3. rag_search\n",
    "   - Searches through knowledge base documents for information\n",
    "   - Input format: {{\"query\": \"your search query\", \"max_results\": 3}}\n",
    "   - Use this when the user asks about concepts, definitions, or information not in the calendar\n",
    "\n",
    "Use this format for your responses:\n",
    "\n",
    "Thought: [Explain your reasoning about what to do next]\n",
    "Action: [tool_name]\n",
    "Action Input: {{\"key\": \"value\"}}\n",
    "\n",
    "After receiving an observation, you can either:\n",
    "1. Continue with another Thought/Action/Action Input if you need more information\n",
    "2. Provide a final answer with: Final Answer: [your answer]\n",
    "\n",
    "Important:\n",
    "- Always explain your thinking in the Thought section\n",
    "- Choose the most appropriate tool for the task\n",
    "- For calendar operations, use the MCP tools (mcp_get_upcoming_events, mcp_create_event, etc.)\n",
    "- For knowledge questions, use rag_search\n",
    "- For calculations, use calculator\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ ReAct system prompt created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ReAct Loop Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_react_response(response: str) -> Dict[str, Any]:\n",
    "    \"\"\"Parse the LLM's ReAct-formatted response.\"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    # Extract Thought\n",
    "    thought_match = re.search(r'Thought:\\s*(.+?)(?=\\n(?:Action|Final Answer):|$)', response, re.DOTALL)\n",
    "    if thought_match:\n",
    "        result['thought'] = thought_match.group(1).strip()\n",
    "    \n",
    "    # Check for Final Answer\n",
    "    final_answer_match = re.search(r'Final Answer:\\s*(.+)', response, re.DOTALL)\n",
    "    if final_answer_match:\n",
    "        result['final_answer'] = final_answer_match.group(1).strip()\n",
    "        return result\n",
    "    \n",
    "    # Extract Action\n",
    "    action_match = re.search(r'Action:\\s*(.+?)(?=\\n|$)', response)\n",
    "    if action_match:\n",
    "        result['action'] = action_match.group(1).strip()\n",
    "    \n",
    "    # Extract Action Input\n",
    "    action_input_match = re.search(r'Action Input:\\s*({.+})', response, re.DOTALL)\n",
    "    if action_input_match:\n",
    "        try:\n",
    "            json_str = action_input_match.group(1).strip()\n",
    "            # Clean up common JSON formatting issues\n",
    "            json_str = re.sub(r'\\n\\s*', ' ', json_str)  # Remove newlines\n",
    "            result['action_input'] = json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            result['error'] = f\"Failed to parse action input: {e}\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "async def execute_tool(action: str, action_input: Dict[str, Any]) -> str:\n",
    "    \"\"\"Execute the appropriate tool based on the action.\"\"\"\n",
    "    \n",
    "    if action == \"calculator\":\n",
    "        return calculator_tool(\n",
    "            action_input.get(\"operation\"),\n",
    "            action_input.get(\"a\"),\n",
    "            action_input.get(\"b\")\n",
    "        )\n",
    "    \n",
    "    elif action.startswith(\"mcp_\"):\n",
    "        # MCP calendar tool\n",
    "        tool_name = action[4:]  # Remove 'mcp_' prefix\n",
    "        arguments = action_input.get(\"arguments\", action_input)\n",
    "        return await call_mcp_tool(tool_name, arguments)\n",
    "    \n",
    "    elif action == \"rag_search\":\n",
    "        return rag_search_tool(\n",
    "            action_input.get(\"query\"),\n",
    "            action_input.get(\"max_results\", 3)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        return f\"Error: Unknown tool '{action}'\"\n",
    "\n",
    "\n",
    "async def run_react_agent(user_question: str, max_iterations: int = 5, verbose: bool = True):\n",
    "    \"\"\"Run the ReAct agent loop.\"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*70)\n",
    "        print(f\"USER QUESTION: {user_question}\")\n",
    "        print(\"=\"*70)\n",
    "    \n",
    "    system_prompt = create_react_system_prompt()\n",
    "    conversation_history = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_question}\n",
    "    ]\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"ITERATION {iteration + 1}\")\n",
    "            print(\"=\"*70)\n",
    "        \n",
    "        # Get LLM response\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=conversation_history,\n",
    "            stream=False,\n",
    "        )\n",
    "        \n",
    "        llm_output = response.choices[0].message.content\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{llm_output}\")\n",
    "        \n",
    "        # Parse the response\n",
    "        parsed = parse_react_response(llm_output)\n",
    "        \n",
    "        # Check if we have a final answer\n",
    "        if 'final_answer' in parsed:\n",
    "            if verbose:\n",
    "                print(\"\\n\" + \"=\"*70)\n",
    "                print(\"FINAL ANSWER:\")\n",
    "                print(\"=\"*70)\n",
    "                print(parsed['final_answer'])\n",
    "                print(\"=\"*70)\n",
    "            return parsed['final_answer']\n",
    "        \n",
    "        # Execute the action if we have one\n",
    "        if 'action' in parsed and 'action_input' in parsed:\n",
    "            action = parsed['action']\n",
    "            action_input = parsed['action_input']\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nüîß Executing: {action}\")\n",
    "                print(f\"üì• Input: {json.dumps(action_input, indent=2)}\")\n",
    "            \n",
    "            # Execute the tool\n",
    "            tool_result = await execute_tool(action, action_input)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nüìä Observation:\")\n",
    "                result_preview = tool_result[:300] + \"...\" if len(tool_result) > 300 else tool_result\n",
    "                print(result_preview)\n",
    "            \n",
    "            # Add observation to conversation\n",
    "            observation_text = f\"Observation: {tool_result}\"\n",
    "            conversation_history.append({\"role\": \"assistant\", \"content\": llm_output})\n",
    "            conversation_history.append({\"role\": \"user\", \"content\": observation_text})\n",
    "        else:\n",
    "            # LLM didn't follow format properly\n",
    "            error_msg = \"Please follow the Thought/Action/Action Input format or provide a Final Answer.\"\n",
    "            if verbose:\n",
    "                print(f\"\\n‚ö†Ô∏è  {error_msg}\")\n",
    "            conversation_history.append({\"role\": \"assistant\", \"content\": llm_output})\n",
    "            conversation_history.append({\"role\": \"user\", \"content\": error_msg})\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚ö†Ô∏è  WARNING: Max iterations reached without final answer\")\n",
    "        print(\"=\"*70)\n",
    "    \n",
    "    return \"I couldn't find an answer within the iteration limit.\"\n",
    "\n",
    "print(\"‚úÖ ReAct agent is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Test the Agent!\n",
    "\n",
    "Now let's see the agent in action. Watch how it autonomously chooses the right tool(s) for each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Using the Calculator\n",
    "\n",
    "The agent should recognize this needs a calculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_react_agent(\"What is 847 multiplied by 923?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Using MCP Calendar\n",
    "\n",
    "The agent should use the calendar MCP tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_react_agent(\"What events do I have coming up in the next 7 days?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Using RAG Search\n",
    "\n",
    "The agent can use RAG to search documents, this is also referred to as Agentic RAG.  \n",
    "\n",
    "**Note**: If this doesn't work, make sure that you have ingested the Canopy document into the RAG database in your canopy project by running through `5-rag/2-intro-to-RAG.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_react_agent(\"What is the structure of Canopy in botany?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Multi-step Reasoning\n",
    "\n",
    "This requires the agent to:\n",
    "1. Search calendar for events\n",
    "2. Perform a calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_react_agent(\"How many events do I have in the next week, multiplied by 2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Difficult Requests\n",
    "\n",
    "Here is a couple of more difficult requests for the agent.  \n",
    "Run them and see if it manages to do them, and if not, why do you think it fails?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_react_agent(\"Tell me about my schedule and what Canopy means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_react_agent(\"Create a meeting for tomorrow at 2pm called 'Team Sync'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Implications\n",
    "\n",
    "Agentic seems fantastic, and it is, but there are drawbacks to be aware of when using agentic workflows.\n",
    "\n",
    "- **Cost**: Each iteration = 1 LLM call = $$$\n",
    "- **Latency**: More reasoning = slower responses\n",
    "- **Reliability**: Since there is more context, agents can easier make misstakes, especially if there are a lot of tools\n",
    "- **Debugging**: Multi-step reasoning is hard to debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Your Own!\n",
    "\n",
    "Now it's your turn. Try questions that:\n",
    "- Require multiple different tools\n",
    "- Need reasoning about which tool to use\n",
    "- Combine calendar, knowledge, and computation\n",
    "\n",
    "See how well the agent handles them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn! Try your own questions:\n",
    "await run_react_agent(\"YOUR QUESTION HERE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
